(window.webpackJsonp=window.webpackJsonp||[]).push([[384],{454:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return l})),a.d(t,"metadata",(function(){return o})),a.d(t,"toc",(function(){return s})),a.d(t,"default",(function(){return b}));var n=a(3),r=a(7),i=(a(0),a(703)),l={title:"project_build script"},o={unversionedId:"database/database-building/build-script",id:"version-4.0.0/database/database-building/build-script",isDocsHomePage:!1,title:"project_build script",description:"To run a full build of InterMine, you must use the project_build script. This is a Perl program that reads a project.xml file and loads each source in turn. This makes multiple calls to Gradle to avoid memory problems encountered when running many Java task sequentially from Gradle. It also has the option of dumping the production database during the build and recovering from these dumps in case of problems.",source:"@site/versioned_docs/version-4.0.0/database/database-building/build-script.md",slug:"/database/database-building/build-script",permalink:"/im-docs/docs/4.0.0/database/database-building/build-script",editUrl:"https://github.com/intermine/im-docs/edit/master/versioned_docs/version-4.0.0/database/database-building/build-script.md",version:"4.0.0",sidebar:"version-4.0.0/someSidebar",previous:{title:"Database Build",permalink:"/im-docs/docs/4.0.0/database/database-building/index"},next:{title:"Project XML",permalink:"/im-docs/docs/4.0.0/database/database-building/project-xml"}},s=[{value:"Command line options",id:"command-line-options",children:[]},{value:"Running a Single Datasource",id:"running-a-single-datasource",children:[]},{value:"Running a Custom Datasource",id:"running-a-custom-datasource",children:[]}],c={toc:s};function b(e){var t=e.components,a=Object(r.a)(e,["components"]);return Object(i.b)("wrapper",Object(n.a)({},c,a,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,"To run a full build of InterMine, you must use the ",Object(i.b)("inlineCode",{parentName:"p"},"project_build")," script. This is a Perl program that reads a project.xml file and loads each source in turn. This makes multiple calls to Gradle to avoid memory problems encountered when running many Java task sequentially from Gradle. It also has the option of dumping the production database during the build and recovering from these dumps in case of problems."),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"Note"),"\nThis script requires the Expect and XML::Parser::PerlSAX Text::Glob perl modules - install with: ",Object(i.b)("inlineCode",{parentName:"p"},"sudo cpan -i XML::Parser::PerlSAX Expect Text::Glob")),Object(i.b)("p",null,"Download the file from the intermine-scripts repository:"),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{className:"language-bash"}),"flymine $ wget https://raw.githubusercontent.com/intermine/intermine-scripts/master/project_build\n")),Object(i.b)("p",null,"Run the build script from the mine directory:"),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{className:"language-bash"}),"flymine $ ./project_build -b -v server_name /some/dump/location/dump_file_prefix\n")),Object(i.b)("p",null,"The ",Object(i.b)("inlineCode",{parentName:"p"},"server_name")," is hostname of the machine where the ",Object(i.b)("inlineCode",{parentName:"p"},"pg_dump")," command should be run. If you are running ",Object(i.b)("inlineCode",{parentName:"p"},"project_build")," on the same machine as PostgreSQL then you should specify ",Object(i.b)("inlineCode",{parentName:"p"},"localhost")," as the server name. If the PostgreSQL server is on a remote machine, give its hostname. In that case the script will try to run ",Object(i.b)("inlineCode",{parentName:"p"},"pg_dump")," on the remote machine using ",Object(i.b)("inlineCode",{parentName:"p"},"ssh"),". This makes dumping a little faster and allows for the case where ",Object(i.b)("inlineCode",{parentName:"p"},"/some/dump/location/dump_file_prefix")," is only visible on the remote machine."),Object(i.b)("p",null,"Dumps are performed when a source has ",Object(i.b)("inlineCode",{parentName:"p"},"dump=true")," in its ",Object(i.b)("inlineCode",{parentName:"p"},"project.xml")," definition:"),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{className:"language-markup"}),'<source name="uniprot-malaria" type="uniprot" dump="true">\n  <property name="uniprot.organisms" value="36329"/>\n  <property name="src.data.dir" location="/data/flyminebuild/malaria/uniprot/7.7/36329"/>\n</source>\n')),Object(i.b)("p",null,"In this example, the dump will be made immediately after the ",Object(i.b)("inlineCode",{parentName:"p"},"uniprot-malaria")," source has been ''successfully'' merged."),Object(i.b)("p",null,"Once all sources are integrated ",Object(i.b)("inlineCode",{parentName:"p"},"project_build")," will run any post-processing steps ","(","also configured in the ",Object(i.b)("inlineCode",{parentName:"p"},"project.xml"),")","."),Object(i.b)("p",null,"It is also possible to run individual integrate and post-process steps separately, see below."),Object(i.b)("h2",{id:"command-line-options"},"Command line options"),Object(i.b)("p",null,"The ",Object(i.b)("inlineCode",{parentName:"p"},"project_build")," script accepts the following flags:"),Object(i.b)("table",null,Object(i.b)("thead",{parentName:"table"},Object(i.b)("tr",{parentName:"thead"},Object(i.b)("th",Object(n.a)({parentName:"tr"},{align:"left"})),Object(i.b)("th",Object(n.a)({parentName:"tr"},{align:"left"})))),Object(i.b)("tbody",{parentName:"table"},Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",Object(n.a)({parentName:"tr"},{align:"left"}),"-v"),Object(i.b)("td",Object(n.a)({parentName:"tr"},{align:"left"}),"is passed to ant to make it run in verbose mode, ant output can be seen in pbuild.log")),Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",Object(n.a)({parentName:"tr"},{align:"left"}),"-l"),Object(i.b)("td",Object(n.a)({parentName:"tr"},{align:"left"}),"attempt to restart by reading the last dump file ","(","see note below",")")),Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",Object(n.a)({parentName:"tr"},{align:"left"}),"-b"),Object(i.b)("td",Object(n.a)({parentName:"tr"},{align:"left"}),"run build-db before starting build and drop any existing backup databases ","(","created when using the -t flag",")")),Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",Object(n.a)({parentName:"tr"},{align:"left"}),"-V"),Object(i.b)("td",Object(n.a)({parentName:"tr"},{align:"left"}),"set the release number to pass to gradle ","(","as -Prelease=release","_","number",")")))),Object(i.b)("p",null,"Dump files take the name ",Object(i.b)("inlineCode",{parentName:"p"},"dump_file_prefix"),".final."),Object(i.b)("p",null,"Running project","_","build with '''",Object(i.b)("inlineCode",{parentName:"p"},"-l"),"''' will reload the latest dump ","(","if any",")"," with ",Object(i.b)("inlineCode",{parentName:"p"},"dump_file_prefix")," and restart the build from that point."),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"Note"),"\nYou must use the full path to the dump file, e.g. ",Object(i.b)("inlineCode",{parentName:"p"},"/some/dump/location/dump_file_prefix")),Object(i.b)("h2",{id:"running-a-single-datasource"},"Running a Single Datasource"),Object(i.b)("p",null,"Before starting the build process you will need to set up the appropriate properties and then initialise your database with this command:"),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{className:"language-bash"}),"flymine $ ./gradlew builddb\n")),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"Note"),"\nRunning the ",Object(i.b)("inlineCode",{parentName:"p"},"builddb")," target will drop the current database and create a new, blank database."),Object(i.b)("p",null,"To run a data source, run this command in your mine directory, specifying the source name ","(","as it appears in project.xml",")",":"),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{className:"language-bash"}),"flymine $ ./gradlew integrate -Psource=uniprot --stacktrace\n")),Object(i.b)("p",null,"Most sources have multiple stages in retrieving data, to run just one stage use:"),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{className:"language-bash"}),"flymine $ ./gradlew integrate -Psource=uniprot -Paction=load --stacktrace\n")),Object(i.b)("p",null,"The stages are:"),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"preretrieve")),Object(i.b)("p",null,"pre-processing that is done"),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"retrieve")),Object(i.b)("p",null,"load data from source database/files into an items database"),Object(i.b)("p",null,Object(i.b)("strong",{parentName:"p"},"load")),Object(i.b)("p",null,"read from a target items database and integrate into the production database"),Object(i.b)("p",null,"See ",Object(i.b)("inlineCode",{parentName:"p"},"/system-requirements/software/gradle/index")," for the full list of common Gradle tasks, or run ",Object(i.b)("inlineCode",{parentName:"p"},"./gradlew tasks")," to see the list of available tasks on the command line."),Object(i.b)("h2",{id:"running-a-custom-datasource"},"Running a Custom Datasource"),Object(i.b)("p",null,"The build script expects the data source to be on the classpath already. If you are using a data source provided by InterMine, that parser will be put on the classpath for you. If you are using a custom source, you will need to put it on the classpath yourself. You can use the Gradle Maven plugin task ",Object(i.b)("inlineCode",{parentName:"p"},"install")," to compile your Java code, build the JAR and put on your classpath."),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{className:"language-bash"}),"# run the install task to build your JAR\nflymine-bio-sources $ ./gradlew install\n")),Object(i.b)("pre",null,Object(i.b)("code",Object(n.a)({parentName:"pre"},{className:"language-bash"}),"# you can install a single source\nflymine-bio-sources $ ./gradlew rnai:install\n")),Object(i.b)("p",null,"The ",Object(i.b)("inlineCode",{parentName:"p"},"install"),' task will place the JAR in the Maven directory \\"~/.m2/repository\\".'))}b.isMDXComponent=!0},703:function(e,t,a){"use strict";a.d(t,"a",(function(){return p})),a.d(t,"b",(function(){return m}));var n=a(0),r=a.n(n);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var c=r.a.createContext({}),b=function(e){var t=r.a.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=b(e.components);return r.a.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},d=r.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=b(a),d=n,m=p["".concat(l,".").concat(d)]||p[d]||u[d]||i;return a?r.a.createElement(m,o(o({ref:t},c),{},{components:a})):r.a.createElement(m,o({ref:t},c))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,l=new Array(i);l[0]=d;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:n,l[1]=o;for(var c=2;c<i;c++)l[c]=a[c];return r.a.createElement.apply(null,l)}return r.a.createElement.apply(null,a)}d.displayName="MDXCreateElement"}}]);